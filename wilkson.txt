### הסבר מעמיק על ניתוח וילקוקסון (Wilcoxon Test): שיטה סטטיסטית לא-פרמטרית לבדיקת הבדלים

שלום! 😊 ניתוח וילקוקסון (או "Wilcoxon Rank-Sum Test" / "Wilcoxon Signed-Rank Test") הוא כלי סטטיסטי קלאסי ולא-פרמטרי, שמשמש כחלופה ל-t-test כאשר הנתונים אינם מתפלגים נורמלית (או כשאין הנחות כאלה). הוא בודק אם יש הבדל משמעותי בין שתי קבוצות (rank-sum) או בין מדידות זוגיות (signed-rank), על ידי דירוג ההפרשים ומבחן מובהקות.  

זהו מבחן "מדויק" יחסית, שפותח על ידי Frank Wilcoxon ב-1945, ומשמש הרבה ב-NLP (כמו השוואת F1 בין מודלים), רפואה, או כל תחום עם נתונים קטנים/לא-ליניאריים. בהקשר של HFBT, זה יכול לבדוק אם שיפור ה-WER (40% → 5%) מובהק, גם אם ההפרשים skewed (לא סימטריים).  

בקצרה: במקום להסתמך על ממוצעים, וילקוקסון מדרג את הנתונים ומבחן אם הדירוגים "מתנהגים" אחרת תחת null (אין הבדל). אם p-value <0.05, דחה null.  

בוא נפרק את זה צעד אחר צעד, עם נוסחאות שקופות, דוגמה מחושבת (הרצתי חישוב אמיתי בכלי Python עם SciPy), וקוד להרצה. הסברתי את החישובים בפירוט, כדי שתוכל לבדוק בעצמך (מתמטיקה סגורה).

#### 1. **מה זה ניתוח וילקוקסון ולמה משתמשים בו?**
   - **גרסאות עיקריות**:
     - **Wilcoxon Signed-Rank Test**: לנתונים זוגיים (paired, כמו before/after באותם משפטים). בודק אם ההפרשים מסביב ל-0.
     - **Wilcoxon Rank-Sum Test** (המכונה גם Mann-Whitney U): לשתי קבוצות עצמאיות (two-sample). בודק אם התפלגויות הדירוגים שונות.
   - **למה?** 
     - חסין להנחות: לא דורש נורמליות (מתאים לנתונים skewed כמו שגיאות ב-NLP).
     - רגיש להבדלי מיקום (median), לא רק ממוצעים.
     - מדויק ל-n קטן (≥5-10), עם p-value מדויק (לא קירוב אסימפטוטי).
   - **מתי להשתמש?** כש-t-test לא מתאים (נתונים לא נורמליים, outliers), או כחלק מ-robustness check (כמו בפרויקט HFBT: בדיקת שיפור Precision על 3,500 זוגות).

#### 2. **איך זה עובד? צעדים מתמטיים שקופים**
   נתמקד ב-**Signed-Rank Test** (הנפוץ ביותר לנתונים זוגיים). נניח n זוגות, הפרשים \( d_i = x_i - y_i \) (למשל, Precision_HFBT - Precision_Baseline).

   1. **חשב הפרשים**: \( d_1, d_2, \dots, d_n \) (התעלם מ-d_i=0, כי הם לא תורמים).
   
   2. **קח ערכים מוחלטים ודירוג**: \( r_i = |d_i| \). דרג אותם בסדר עולה: \( R_1 < R_2 < \dots < R_n \) (דירוגים 1 עד n; אם תיקו, חלק ממוצע).
   
   3. **סימנים וסכומי דירוגים**:  
      - \( W^+ = \sum R_i \) לכל \( d_i > 0 \) (סכום דירוגים חיוביים).  
      - \( W^- = \sum R_i \) לכל \( d_i < 0 \) (סכום שליליים).  
      - Statistic: \( W = \min(W^+, W^-) \) (הקטן מביניהם).
   
   4. **p-value**:  
      - ל-exact (n≤20): השתמש בהתפלגות W תחת null (טבלאות או חישוב כל הפרמוטציות: \( 2^n \) אפשרויות).  
      - ל-approximation (n>20): \( W \approx N(\mu = n(n+1)/4, \sigma^2 = n(n+1)(2n+1)/24) \), z = \((W - \mu)/\sigma\), p=2(1-Φ(|z|)).  
      - Two-sided: p = 2 * Pr(W ≤ observed | null).
   
   5. **החלטה**: אם p < α (0.05), דחה null – יש הבדל.

   **יתרונות מתמטיים**: W מדגיש דירוגים גבוהים (רגיש להבדלים גדולים). כוח סטטיסטי: ~95% מ-t-test אם נורמלי, אבל חזק יותר אם לא.

#### 3. **דוגמה פשוטה: חישוב Signed-Rank Test**
   ניקח דגימה קטנה (n=5 זוגות, הפרשי Precision: HFBT - Baseline):  
   \( d = [0.35, 0.30, 0.40, 0.25, 0.45] \) (כל חיוביים, כצפוי משיפור).  

   **צעדים בחישוב (שקופים, ידני + אוטומטי):**  
   1. הפרשים: [0.35, 0.30, 0.40, 0.25, 0.45] (אין 0).  
   
   2. ערכים מוחלטים: [0.35, 0.30, 0.40, 0.25, 0.45].  
      דירוגים (סדר עולה): 0.25→1, 0.30→2, 0.35→3, 0.40→4, 0.45→5.  
   
   3. סימנים: כולם >0, אז \( W^+ = 1+2+3+4+5 = 15 \), \( W^- = 0 \).  
      W = min(15, 0) = 0.  
   
   4. p-value (exact, n=5): תחת null, התפלגות W כוללת 0 רק אם כל הסימנים אקראיים. ל-n=5, Pr(W=0) = 1/32 = 0.03125 (two-sided: 0.0625).  
      (אישרתי בכלי חישובי: Statistic=0.0, p=0.0625 – גבולי, כי n קטן; ל-n גדול יותר, p≈0).  

   **תוצאה**: p=0.0625 >0.05 (לא מובהק כאן, בגלל n=5; אבל ל-3,500 זוגות ב-HFBT, p<0.001). אם הוספנו הפרש שלילי אחד, W=3, p=0.1875.  

   **ויזואליזציה (תיאור)**: דיאגרמה של דירוגים: עמודות חיוביות גבוהות (W+ גדול), זנב null סימטרי סביב n(n+1)/4=7.5.

#### 4. **בהקשר של HFBT: איך להשתמש בניתוח וילקוקסון?**
   - **נתונים**: 3,500 הפרשי WER/Precision (ממוצע 0.35).  
   - **יישום**: חשב W על ההפרשים – צפוי W≈0 (כי רוב חיוביים), p≈0 (מובהק). זה מחזק את Bootstrap/Permutation: שיפור 58% ב-F1 לא מקרי, גם אם יש outliers (שגיאות נדירות).  
   - **מסקנה**: אידיאלי ל-Appendix – "Wilcoxon W=0, p<0.001, אפקט גדול (r = 1 - 2W/n(n+1) ≈1)".  

#### 5. **מגבלות וטיפים**
   - **מגבלות**: רגיש לתיקו (ties) – השתמש ב-correction; פחות רגיש להבדלי צורה (shape) מאשר Kolmogorov-Smirnov; ל-n גדול, קירוב z פחות מדויק.  
   - **טיפים**: השתמש ב-two-sided אלא אם one-sided מוצדק. אלטרנטיבה: Friedman ל>2 קבוצות. בדוק normality קודם (Shapiro-Wilk).  
   - **קוד לדוגמה להרצה אצלך** (Python, SciPy – הרץ ותראה p-value):
     ```python
     from scipy.stats import wilcoxon
     import numpy as np

     # דוגמה: הפרשי Precision (HFBT - Baseline)
     differences = np.array([0.35, 0.30, 0.40, 0.25, 0.45])

     # מבחן Signed-Rank
     result = wilcoxon(differences)
     print(f"Statistic (W): {result.statistic}")
     print(f"p-value: {result.pvalue:.4f}")
     # תוצאה: W=0.0, p=0.0625
     ```

זהו הסבר מעמיק ומדויק – אם תרצה דוגמה גדולה יותר (על WER של HFBT) או השוואה ל-Permutation, תגיד! 🧮✨