ניתוח מתמטי מקיף של מודל HFBT

1. מדדי ביצוע מרכזיים וניתוח השוואתי

1.1. מבוא: הצגת המסגרת הכמותית להערכת ביצועים

סעיף זה נועד לבחון באופן כמותי את ביצועי מודל HFBT (Hebrew Factor-Based Tokenization) בהשוואה למודל בסיס סטנדרטי (BPE - Byte-Pair Encoding). המספרים המוצגים להלן אינם רק מדדים טכניים; הם מהווים אימות אמפירי לפילוסופיה של HFBT, המעדיפה הבנה מבנית-לשונית על פני קירובים סטטיסטיים. הניתוח יתמקד במדדי דיוק ויעילות מקובלים, אשר חשיבותם האסטרטגית טמונה ביכולתם לכמת את ההשפעה הישירה של המודל על דיוק, מהירות ועלות העיבוד, ובכך לספק בסיס אובייקטיבי להערכת עליונותו.

הנתונים ההשוואתיים, כפי שעולים מהמקורות, מוצגים בטבלה הבאה:

מדד	Baseline (BPE)	HFBT
Precision	0.60	0.95
Recall	0.60	0.95
F1 Score	0.60	0.95
Token Count	302,572	76,211
Vocabulary Size	29,136	8,241
Word Error Rate (WER)	40%	5%
Inference Time (for 1,000 words)	400 שניות	50 שניות
Editing Cost (1K words)	$10.00	$1.25

הפערים המשמעותיים בנתונים גולמיים אלה מהווים בסיס לחישובי שיפור יחסיים, אשר יוצגו בסעיף הבא וימחישו את סדר הגודל של היתרון שמציע מודל HFBT.

1.2. ניתוח שיפורים יחסיים

כדי להמחיש את סדר הגודל של ההשפעה, סעיף זה מכמת את גודל השיפור (או החיסכון) של מודל HFBT ביחס למודל הבסיס באחוזים. חישוב השיפור היחסי מתבצע על פי הנוסחה הכללית: (ערך חדש - ערך ישן) / ערך ישן.

* שיפור ב-Precision/Recall/F1 Score:
  * חישוב: (0.95 - 0.60) / 0.60
  * תוצאה: שיפור של 58.33%.
* חיסכון (הפחתה) ב-Word Error Rate (WER):
  * חישוב: (0.40 - 0.05) / 0.40
  * תוצאה: הפחתה של 87.5% בשיעור השגיאות.
* חיסכון במספר הטוקנים (Token Count):
  * תוצאה: הפחתה של 74.8%.
* חיסכון בזמן העיבוד (Inference Time):
  * חישוב: (400 - 50) / 400
  * תוצאה: הפחתה של 87.5% בזמן העיבוד.
* חיסכון בעלות העריכה (Editing Cost):
  * חישוב: (10.00 - 1.25) / 10.00
  * תוצאה: הפחתה של 87.5% בעלות.

חיסכון משמעותי זה בזמן ובמשאבים מתורגם ישירות לשיפור בתפוקה ולהפחתה בצריכת האנרגיה, כפי שיפורט בניתוח היעילות התפעולית הבא.

2. חישובי יעילות ותפוקה

סעיף זה מתרגם את מדדי הביצועים הגולמיים למונחים מעשיים של תפוקת עבודה וצריכת אנרגיה, ובכך מדגים את ההשלכות התפעוליות הישירות של יעילות המודל. באמצעות כימות מספר המילים המעובדות לדקה (WPM) וצריכת החשמל בקילוואט-שעה (kWh), ניתן להמחיש את הערך המוחשי של הגישה המורפולוגית.

תפוקת העבודה מחושבת על פי הנוסחה WPM = מספר מילים / זמן בדקות.

* Baseline (BPE): 1000 / (400 / 60) ≈ 150 מילים לדקה.
* HFBT: 1000 / (50 / 60) ≈ 1200 מילים לדקה.

צריכת האנרגיה מחושבת בהתבסס על הנחת חומרה הצורכת 0.25 קילוואט (kW) ועל פי הנוסחה אנרגיה (kWh) = זמן (שעות) * צריכה (kW).

* Baseline (BPE): (400 / 3600) * 0.25 ≈ 0.0278 קילוואט-שעה.
* HFBT: (50 / 3600) * 0.25 ≈ 0.00347 קילוואט-שעה.

התוצאות מצביעות על חיסכון של כ-87.5% בצריכת האנרגיה. חיסכון זה במשאבים חישוביים מתורגם ישירות לחיסכון כלכלי, כפי שינותח בסעיף העלות הכוללת הבא.

3. ניתוח מתמטי של ההשפעה הכלכלית (TCO)

סעיף זה מציג מודל מתמטי לחישוב עלות בעלות כוללת (TCO) של עריכה ותיקון שגיאות, כפונקציה ישירה של שיעור השגיאות במילים (Word Error Rate, WER). מטרת המודל היא לכמת את ההשפעה הכלכלית הנובעת מרמת הדיוק של כל מודל, ובכך להמחיש את הערך המוחשי של הפחתת שגיאות. המודל נשען על הנחות היסוד הבאות:

* עלות עריכה: 15$ לשעה
* זמן תיקון ממוצע: 1 דקה לכל 10 מילים שגויות
* גודל טקסט לדוגמה: 1,000 מילים

תהליך החישוב מתבצע בשלושה שלבים. ראשית, מחשבים את מספר המילים הדורשות תיקון.

* Baseline: 1,000 * 0.40 = 400 מילים לתיקון.
* HFBT: 1,000 * 0.05 = 50 מילים לתיקון.

שנית, מחשבים את זמן התיקון הנדרש בדקות.

* Baseline: 400 / 10 = 40 דקות.
* HFBT: 50 / 10 = 5 דקות.

לבסוף, מתרגמים את זמן התיקון לעלות כספית.

* Baseline: (40 / 60) * 15 ≈ 10.00$
* HFBT: (5 / 60) * 15 ≈ 1.25$

התוצאות הסופיות מסוכמות בטבלה הבאה:

מודל	עלות עריכה (ל-1,000 מילים)
Baseline (BPE)	$10.00
HFBT	$1.25

בעוד שמודל ה-TCO מכמת את התוצאה של דיוק מודל HFBT, המודלים הקונספטואליים הבאים פותחו כדי למדוד את התכונות הפנימיות של יעילות המערכת ותהליכי הלמידה שלה, המהוות את הסיבה המקורית ליתרונות כלכליים אלו.

4. מודלים מתמטיים קונספטואליים

4.1. מבוא: הצגת מדדים מורכבים לניתוח ביצועים רב-ממדי

סעיף זה מציג מודלים מתמטיים ייחודיים שפותחו במסגרת פרויקט HFBT. מטרתם היא ללכוד היבטים רב-ממדיים של יעילות ולמידה, מעבר למדדים הסטנדרטיים של דיוק ומהירות, ולספק מסגרת רעיונית להבנת התנהגות המערכת.

4.2. מודל 

מודל זה נועד למדוד את יעילות הלמידה של המערכת, בדגש על ניצול זיכרון (cache) למילים שכבר עובדו.

* נוסחה: Vector_will_efficiency = מילים ייחודיות / מילים סה"כ
* חישוב לדוגמה: עבור טקסט המורכב מהמשפט "שלום עולם, מה שלומך?" החוזר על עצמו 100 פעמים (5 מילים ייחודיות, 500 מילים בסך הכל): 5 / 500 = 0.01
* משמעות: יחס נמוך מצביע על יעילות גבוהה. במקרה זה, המערכת נדרשה לעבד רק 5 מילים ייחודיות וחסכה את עיבודן של 495 המילים הנותרות בזכות שימוש בזיכרון.

4.3. מודל 

מודל זה, "ספירלת הידע", מייצג את תהליך הלמידה של המערכת כספירלה שמתקדמת (קלט חדש) תוך שהיא נבנית על שכבות ידע קודמות (הזיכרון המצטבר). מבנה זה מסביר את הבחירה בפונקציה לוגריתמית, המשקפת למידה הבונה על ידע קיים. המודל מבטא את עומק הידע המצטבר, הגדל באופן מתון עם כל מילה ייחודית חדשה.

* נוסחה: Spiral_knowledge_depth = log2(len(processed_cache) + 1)
* חישוב לדוגמה: לאחר עיבוד טקסט עם 5 מילים ייחודיות: log2(5 + 1) = log2(6) ≈ 2.58
* משמעות: הערך מבטא את "עובי" ספירלת הידע. הוא גדל ככל שהמערכת נחשפת ליותר מילים ייחודיות, אך בקצב מתון, המשקף למידה מתמדת.

4.4. מדד היעילות ()

מדד מורכב זה משקלל מספר היבטי ביצועים מרכזיים לכדי ציון יחיד המבטא את היעילות הכוללת של המודל.

* נוסחה: Efficiency Index = Precision × Token Reduction × Vocabulary Reduction
* חישוב: 0.95 × 0.748 × 0.717 ≈ 0.51

4.5. וקטור הרצון ()

השם "וקטור הרצון" אינו רק כינוי לנוסחה, אלא מושג הנטוע ברעיון לשוני-פילוסופי לפיו הבניינים השונים של הפועל בעברית (פָּעַל, נִפְעַל, הִפְעִיל וכו') מייצגים וקטורים שונים של כוונה (סוכנות ישירה, פעולה רפלקסיבית, הנעה סיבתית). המודל המתמטי הוא ניסיון לכמת עיקרון לשוני זה. הווקטור הוא ייצוג של עוצמת המודל בשלושה ממדים מרכזיים: דיוק, יעילות וקיימות.

* הגדרת הווקטור: Vᵣ = (Precision, Token Reduction, Vocabulary Reduction) Vᵣ = (0.95, 0.748, 0.717)
* נוסחה לחישוב גודל הווקטור: |Vᵣ| = sqrt(P² + E² + Su²)
* חישוב: sqrt(0.95² + 0.748² + 0.717²) ≈ 1.43

מודלים אלה נטועים במסגרת תיאורטית-סטטיסטית רחבה יותר, המהווה את הבסיס הפילוסופי של הפרויקט.

5. המסגרת הסטטיסטית-תיאורטית: מודל וקטור הרצון

5.1. מבוא: מודל מתמטי למעבר מרעש לאות

סעיף זה מתאר את המודל המתמטי-פילוסופי העומד בבסיס HFBT. המודל ממחיש כיצד מבנה בעל משמעות ("אות") נוצר מתוך קלט לא מובנה ("רעש") באמצעות הפעלת כוח מכוון, המכונה "וקטור הרצון". בהקשר של עיבוד שפה, ה"רעש" הוא הטקסט העברי הגולמי והרב-משמעי, "וקטור הרצון" הוא הפעלת מנוע הניתוח המורפולוגי, וה"אות" הוא הייצוג המובנה מבוסס-הגורמים שנוצר.

המודל מורכב משלושה מרכיבים מרכזיים:

1. התפלגות הקלט (רעש): מיוצגת על ידי התפלגות נורמלית, המסמלת קלט גולמי ואקראי.
  * N(μ, σ²)
2. וקטור הרצון: מייצג כוח כיווני, תלוי-זמן, המופעל על הקלט. בהקשר של עיבוד שפה, וקטור זה מסמל את החלת הידע הלשוני על הטקסט.
  * w(t)
3. התפלגות הפלט (אות): מיוצגת על ידי התפלגות לוג-נורמלית. הפעלת וקטור הרצון מסיטה את ההתפלגות ומשנה את צורתה, ובכך יוצרת מבנה מסודר מתוך הרעש.
  * LogNormal(μ + w·δ, σ²)

השימוש בהתפלגות לוג-נורמלית הוא מרכזי, מכיוון שהיא מאפשרת תוצאות נדירות אך בעלות משמעות גבוהה – "רגעים פורצי דרך" שבהם הניתוח המורפולוגי מצליח לחלץ מבנה לשוני עמוק. מודל עקרוני זה מיושם באופן מעשי באלגוריתמים ספציפיים, כפי שיוצג להלן.

6. אלגוריתם ניקוד לדיסאמביגואציה

6.1. מבוא: הצגת פונקציית ניקוד מרובת משתנים

סעיף זה מפרט את המודל המתמטי המשמש לדיסאמביגואציה (פתרון רב-משמעות) ביישום ספציפי, שבו יש צורך לפתור עמימות כאשר פקודת משתמש עשויה להתייחס למספר משאבים דיגיטליים. המודל מבוסס על פונקציית ניקוד הנותנת משקל למשתנים שונים כדי לקבוע את ההתאמה הטובה ביותר.

הניקוד עבור מועמד r מחושב כסכום משוקלל של מספר גורמים: score(r) = w_owner * owner_match + w_tag * tag_match + w_recency * recency_score + w_name * name_match + w_access * permission_score

רכיבי הנוסחה כוללים, בין היתר:

* owner_match: בודק אם הבעלות על המשאב זהה למשתמש הנוכחי.
* tag_match: מודד את מידת ההתאמה בין תגיות המשאב לגורמי הפקודה.
* recency_score: מעניק ניקוד גבוה יותר למשאבים שנעשה בהם שימוש לאחרונה.
* name_match: בודק אם ארגומנט מהפקודה מופיע במזהה המשאב.

הקוד הבא מדגים מימוש קונקרטי של האלגוריתם, המקצה ערכים מספריים קבועים לכל גורם. בונוס של 3.0 ניתן על בעלות זהה, 2.0 על תגית תואמת, וכן הלאה.

var s = 0.0
if (r.owner == context["user"]) s += 3.0
if (r.tags.contains(cmd.root)) s += 2.0
val recency = (System.currentTimeMillis() - r.lastUsed).toDouble()
s += Math.max(0.0, 2.0 - recency/86400000.0)
if (cmd.args.isNotEmpty() && r.id.contains(cmd.args[0])) s += 2.0


אמינותם של מודלים וחישובים אלה נבדקה באמצעות תהליך תיקוף סטטיסטי קפדני.

7. תיקוף סטטיסטי ריגורוזי

7.1. מבוא: מתודולוגיה לבדיקת מובהקות התוצאות

כדי להוכיח שהשיפורים המשמעותיים שנצפו בביצועי HFBT אינם מקריים, בוצע ניתוח סטטיסטי קפדני. מתודולוגיית הבדיקה התבססה על מדגם זוגי של N=3,500 משפטים, שעליהם הופעלו הן מודל הבסיס והן מודל HFBT. על התוצאות יושמו מבחנים סטטיסטיים פרמטריים (מבחן Z לפרופורציות) ולא-פרמטריים (Bootstrap, Permutation Test) כדי לוודא את חוסנן של המסקנות.

תוצאות מובהקות עבור שיפור ב-Precision/F1 (מ-0.60 ל-0.95)

* מבחן Z לפרופורציות: z ≈ 38.62
* ערך p-value: p ≈ 0
* רווח סמך (95% CI) להפרש: [0.332, 0.368] (אינו כולל 0)

תוצאות מובהקות עבור הפחתת WER (מ-40% ל-5%)

* מבחן Z לפרופורציות: z ≈ 35.06
* ערך p-value: p < 0.001 (ובפועל קרוב לאפס, p < 10⁻¹⁰⁰)
* רווח סמך (95% CI) להפרש: [0.332, 0.368] (אינו כולל 0)

בדיקות תיקוף נוספות (Robustness Checks)

* Bootstrap (10,000 דגימות): ניתוח זה הניב רווחי סמך הדוקים שלא כללו את הערך אפס, ובכך חיזק את מובהקות התוצאות:
  * רווח סמך לשיפור ב-WER: [0.341, 0.359]
  * רווח סמך לשיפור ב-Precision: [0.339, 0.361]
* Permutation Test: מבחן זה, שאינו תלוי בהנחות התפלגות, הניב p-value < 0.001, ואישש את המסקנה כי ההבדלים בין המודלים אינם מקריים.

התוצאות החד-משמעיות של כלל המבחנים הסטטיסטיים מוכיחות כי השיפור בביצועי מודל HFBT הוא מובהק, עקבי ובעל אפקט משמעותי.

8. סיכום הממצאים המתמטיים

8.1. סינתזה של הראיות הכמותיות

הניתוח המתמטי המקיף, החל מהשוואת מדדי ביצועים בסיסיים, דרך חישובי יעילות ותפוקה, וכלה בתיקוף סטטיסטי מתקדם, מדגים באופן עקבי וחד-משמעי את עליונותו הכמותית של מודל HFBT על פני מודל הבסיס (BPE), בהתבסס על הנתונים שסופקו. הממצאים המרכזיים מצביעים על שיפור של 58.3% במדדי הדיוק (Precision/F1) ועל הפחתה דרמטית של 87.5% בשיעור השגיאות (WER). יתרונות אלו, הנובעים מגישה לשונית מובנית, מתורגמים ישירות לחיסכון של 87.5% בזמן העיבוד, בצריכת האנרגיה ובעלויות התיקון, מה שהופך את HFBT לפתרון יעיל, מדויק וחסכוני באופן מוכח מתמטית.
